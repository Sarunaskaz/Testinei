{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "data_dir = 'PetImages'\n",
    "cat_dir = os.path.join(data_dir, 'Cat')\n",
    "dog_dir = os.path.join(data_dir, 'Dog')\n",
    "\n",
    "#Aprasom kokia dalis tenka mokymui ir testavimui\n",
    "splits = (0.7, 0.15, 0.15)\n",
    "\n",
    "def split_data(directory:str, splits:tuple):\n",
    "    \"\"\"\n",
    "    Funkcija yra skirta suskaidyti pateiktam kataloge esancias nuotraukas i tris naujus katalogus, pagal \n",
    "    pateiktus isskaidymo dydzius\n",
    "\n",
    "    Parametrai:\n",
    "    directory - nuoroda iki failo, kuri norite skaidyti\n",
    "    splits - tuple, su nurodytais kiekiais mokymui, testavimui ir validacijai\n",
    "    \"\"\"\n",
    "    images = os.listdir(directory)\n",
    "    random.shuffle(images)\n",
    "    train_size = int(len(images) * splits[0])\n",
    "    validation_size = int(len(images) * splits[1])\n",
    "    print(validation_size)\n",
    "\n",
    "    train_dir = os.path.join(directory, 'train')\n",
    "    validation_dir = os.path.join(directory, 'validation')\n",
    "    test_dir = os.path.join(directory, 'test')\n",
    "\n",
    "    \n",
    "    \n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        if i < train_size:\n",
    "            shutil.copy(os.path.join(directory, image), os.path.join(train_dir, image))\n",
    "        elif i < train_size + validation_size:\n",
    "            shutil.copy(os.path.join(directory, image), os.path.join(validation_dir, image))\n",
    "        else:\n",
    "            shutil.copy(os.path.join(directory, image), os.path.join(test_dir, image))\n",
    "\n",
    "\n",
    "split_data(cat_dir, splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "data_dir = 'PetImages'\n",
    "cat_dir = os.path.join(data_dir, 'Cat')\n",
    "dog_dir = os.path.join(data_dir, 'Dog')\n",
    "\n",
    "def is_valid_image(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            img.verify()\n",
    "        return True\n",
    "    except (IOError, SyntaxError):\n",
    "        return False\n",
    "    \n",
    "def get_valid_image_files(directory):\n",
    "    \"\"\"Skirta atrinkti į sąrašą tik validžių failų pavadinimus\"\"\"\n",
    "    valid_files = []\n",
    "    for root, _, files in os.walk(directory): # naudojame _ katalogams train, validation, test, nes neketiname jų naudoti\n",
    "        if root != directory:\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if is_valid_image(file_path):\n",
    "                    valid_files.append(file_path)\n",
    "    return valid_files\n",
    "\n",
    "valid_cat_photos = get_valid_image_files(cat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarun\\OneDrive\\Documents\\Code\\Testinei\\mokymai\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_cat_photos))\n",
    "valid_dog_photos = get_valid_image_files(dog_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12489 validated image filenames.\n",
      "Found 12499 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "dataGen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "cat_df = pd.DataFrame({'filename':valid_cat_photos})\n",
    "dog_df = pd.DataFrame({'filename':valid_dog_photos})\n",
    "\n",
    "cat_generator = dataGen.flow_from_dataframe(\n",
    "    dataframe = cat_df,\n",
    "    x_col = 'filename',\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 20,\n",
    "    class_mode = None)\n",
    "\n",
    "dog_generator = dataGen.flow_from_dataframe(\n",
    "    dataframe = dog_df,\n",
    "    x_col = 'filename',\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 20,\n",
    "    class_mode = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "\n",
    "class CombinedGenerator(Sequence):\n",
    "    def __init__(self, *generators):\n",
    "        self.generators = generators\n",
    "        self._num_batches = sum(len(gen) for gen in generators)\n",
    "        self.current_generator = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._num_batches\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        for gen in self.generators:\n",
    "            if idx < len(gen):\n",
    "                batch = gen[idx]\n",
    "                labels = np.array([0] * batch.shape[0]) if gen == cat_generator else np.array([1]* batch.shape[0])\n",
    "                return batch, labels\n",
    "            idx -= len(gen)\n",
    "\n",
    "combined_generator = CombinedGenerator(cat_generator, dog_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (150,150,3)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation = 'relu' ),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1094/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m27s\u001b[0m 178ms/step - accuracy: 0.6641 - loss: 0.6229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarun\\OneDrive\\Documents\\Code\\Testinei\\mokymai\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 171ms/step - accuracy: 0.6653 - loss: 0.6211\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 174ms/step - accuracy: 0.7394 - loss: 0.5259\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 216ms/step - accuracy: 0.8054 - loss: 0.4162\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 133ms/step - accuracy: 0.8759 - loss: 0.2926\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 102ms/step - accuracy: 0.9517 - loss: 0.1342\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    combined_generator,\n",
    "    steps_per_epoch = len(combined_generator),\n",
    "    epochs = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.7607843 , 0.76862746, 0.81960785],\n",
       "         [0.8156863 , 0.83137256, 0.8784314 ],\n",
       "         [0.85490197, 0.87058824, 0.91764706],\n",
       "         ...,\n",
       "         [0.4745098 , 0.40392157, 0.3647059 ],\n",
       "         [0.4627451 , 0.39215687, 0.36078432],\n",
       "         [0.45490196, 0.3882353 , 0.36078432]],\n",
       "\n",
       "        [[0.77254903, 0.78039217, 0.83137256],\n",
       "         [0.8039216 , 0.8156863 , 0.8627451 ],\n",
       "         [0.83137256, 0.84705883, 0.89411765],\n",
       "         ...,\n",
       "         [0.4745098 , 0.40392157, 0.3647059 ],\n",
       "         [0.4627451 , 0.39215687, 0.36078432],\n",
       "         [0.45490196, 0.3882353 , 0.36078432]],\n",
       "\n",
       "        [[0.78431374, 0.7921569 , 0.8392157 ],\n",
       "         [0.7882353 , 0.79607844, 0.84313726],\n",
       "         [0.80784315, 0.81960785, 0.8627451 ],\n",
       "         ...,\n",
       "         [0.47843137, 0.40784314, 0.36862746],\n",
       "         [0.4627451 , 0.4       , 0.36862746],\n",
       "         [0.4627451 , 0.39607844, 0.36862746]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8156863 , 0.8235294 , 0.88235295],\n",
       "         [0.79607844, 0.8039216 , 0.8627451 ],\n",
       "         [0.78431374, 0.79607844, 0.85490197],\n",
       "         ...,\n",
       "         [0.5921569 , 0.5921569 , 0.6       ],\n",
       "         [0.5921569 , 0.5921569 , 0.59607846],\n",
       "         [0.5921569 , 0.5921569 , 0.5921569 ]],\n",
       "\n",
       "        [[0.7921569 , 0.8       , 0.85882354],\n",
       "         [0.7882353 , 0.79607844, 0.85490197],\n",
       "         [0.7764706 , 0.7882353 , 0.84705883],\n",
       "         ...,\n",
       "         [0.58431375, 0.58431375, 0.5921569 ],\n",
       "         [0.58431375, 0.58431375, 0.5882353 ],\n",
       "         [0.58431375, 0.58431375, 0.58431375]],\n",
       "\n",
       "        [[0.78039217, 0.7882353 , 0.84705883],\n",
       "         [0.8       , 0.80784315, 0.8666667 ],\n",
       "         [0.8       , 0.8117647 , 0.87058824],\n",
       "         ...,\n",
       "         [0.5764706 , 0.5764706 , 0.58431375],\n",
       "         [0.57254905, 0.57254905, 0.5764706 ],\n",
       "         [0.57254905, 0.57254905, 0.57254905]]]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((150, 150))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array.astype('float32') / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "preprocess_image('cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Kate\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Suo\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Kate\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Suo\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    prediction = model.predict(img_array)\n",
    "    return 'Suo' if prediction[0][0] > 0.5 else 'Kate'\n",
    "\n",
    "print(predict_image('cat.jpg'))\n",
    "print(predict_image('dog.jpg'))\n",
    "print(predict_image('cat2.jpg'))\n",
    "print(predict_image('dog2.jpg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mokymai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
